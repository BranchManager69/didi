{
  "name": "Llama-3 (8B Balanced)",
  "llm_model": "meta-llama/Meta-Llama-3-8B-Instruct",
  "embed_model": "intfloat/e5-large-v2",
  "collection_name": "degenduel_code_llama3",
  "chunk_size": 4096,
  "chunk_overlap": 512,
  "context_window": 8192,
  "max_new_tokens": 2048,
  "temperature": 0.1
}